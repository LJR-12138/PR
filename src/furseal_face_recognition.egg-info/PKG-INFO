Metadata-Version: 2.4
Name: furseal-face-recognition
Version: 0.1.0
Summary: Fur seal face detection, recognition, and behavior analytics toolkit
Author: Furseal Research Team
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: ultralytics>=8.2.0
Requires-Dist: torch>=2.2
Requires-Dist: torchvision>=0.17
Requires-Dist: torchaudio>=2.2
Requires-Dist: facenet-pytorch>=2.5.3
Requires-Dist: opencv-python>=4.9
Requires-Dist: numpy>=1.26
Requires-Dist: pandas>=2.2
Requires-Dist: scikit-learn>=1.4
Requires-Dist: scipy>=1.11
Requires-Dist: Pillow>=10.3
Requires-Dist: matplotlib>=3.8
Requires-Dist: seaborn>=0.13
Requires-Dist: tqdm>=4.66
Requires-Dist: tyro>=0.6.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: rich>=13.7
Requires-Dist: networkx>=3.2
Requires-Dist: geopandas>=0.14
Requires-Dist: shapely>=2.0
Requires-Dist: pyproj>=3.6
Requires-Dist: exifread>=3.0
Requires-Dist: python-dotenv>=1.0
Requires-Dist: faiss-cpu>=1.8.0
Requires-Dist: plotly>=5.20
Provides-Extra: dev
Requires-Dist: pytest>=8.2; extra == "dev"
Requires-Dist: pytest-cov>=5.0; extra == "dev"
Requires-Dist: black>=24.4; extra == "dev"
Requires-Dist: ruff>=0.5; extra == "dev"
Requires-Dist: mypy>=1.10; extra == "dev"
Requires-Dist: pre-commit>=3.7; extra == "dev"

# Fur Seal Face Intelligence Toolkit

An end-to-end research pipeline for fur-seal face **detection**, **recognition**, and **behavior informatics**. The project leverages transfer learning on modern vision backbones and geospatial analytics to transform raw expedition imagery into actionable insights on fur-seal populations around Victoria.

---

## 1. Project Overview

| Module | Goal | Key Techniques |
| --- | --- | --- |
| Detection | Localise every fur-seal face in expedition imagery | Ultralytics YOLOv8 fine-tuning, custom augmentations |
| Recognition | Tell individuals apart across photos | Face embeddings (FaceNet), metric learning, clustering |
| Behavior Informatics | Understand social/spatial patterns | GPS EXIF mining, spatiotemporal joins, network analytics |

The repository is structured to scale from quick experiments on the light-weight sample dataset to full 30â€¯GB training corpora stored offline.

---

## 2. Getting Started

### 2.1 Create and activate the virtual environment

```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -e .
```

### 2.2 Fetch the datasets

1. **Clone the source repository with Git LFS enabled**
   ```powershell
   git lfs install
   git clone https://github.com/tulip-lab/furseal.git data\furseal
   ```
2. **Datasets of interest**
   - `data/furseal/datasets` â€“ labelled YOLO-format faces for supervised detection.
   - `data/furseal/task_datasets` â€“ large unlabelled corpora used for inference and behavior analysis.

> ðŸ’¡ Store the original 30â€¯GB archives outside of the Git repo. Symbolic links or environment variables can point to the actual storage drive.

### 2.3 Configure paths and hyper-parameters

Copy the template and edit it as needed:

```powershell
Copy-Item configs\example_config.yaml configs\local.yaml
```

Update `configs/local.yaml` to match your data layout.

### 2.4 Quick smoke test

```powershell
python -m scripts.check_setup --config configs\local.yaml
```

This validates dataset paths, GPU availability, and dependency versions.

---

## 3. Workflow

1. **Label audit / augmentation**: Optional scripts prepare custom annotations or expand the training corpus.
2. **Detection training**: Fine-tune YOLOv8 on labelled faces.
3. **Face extraction**: Batch crop detections, quality-filter, and align faces.
4. **Recognition training**: Learn embeddings via FaceNet (metric learning on positive/negative pairs).
5. **Identity clustering**: Use FAISS + DBSCAN/HDBSCAN to group embeddings into individuals.
6. **Behavior analytics**: Merge identities with GPS timestamps to infer co-occurrence patterns.

---

## 4. Command Line Recipes

```powershell
# 1. Convert raw annotations (if you have CSV/COCO etc.)
python -m scripts.prepare_detection_data --config configs\local.yaml

# 2. Fine-tune YOLOv8
python -m scripts.train_detector --config configs\local.yaml

# 3. Run detector on unlabelled archive
python -m scripts.run_detection --config configs\local.yaml --split validation

# 4. Build face embeddings
python -m scripts.build_embeddings --config configs\local.yaml

# 5. Cluster identities
python -m scripts.cluster_identities --config configs\local.yaml

# 6. Behaviour insights
python -m scripts.analyze_behaviour --config configs\local.yaml
```

Each command provides CLI arguments for overrides (see `--help`).

---

## 5. Repository Layout

```
configs/               # YAML configuration templates
notebooks/             # Exploratory analysis & visualisations
scripts/               # CLI entry points that orchestrate the pipeline
src/
  analysis/            # Behaviour informatics & reporting
  data/                # Dataset utilities & download helpers
  detection/           # YOLO pipeline wrappers
  recognition/         # Embedding models & matching logic
  utils/               # Generic helpers (logging, paths, io)
tests/                 # Unit/functional tests
```

---

## 6. Training Guidance

- **Hardware**: A CUDA-capable GPU (â‰¥8â€¯GB VRAM) accelerates both YOLO fine-tuning and FaceNet embedding extraction. CPU-only mode works for prototyping but is slow.
- **Mixed precision**: Enabled by default on GPU to fit larger batches.
- **Checkpointing**: All training scripts log to `outputs/training/<run_name>` with tensorboard-ready metrics.
- **Evaluation**: mAP (detection) and clustering purity/NMI (recognition) reported in logs.

---

## 7. Behaviour Analytics Ideas

- Construct co-occurrence graphs (nodes=individual fur seals, edges=joint sightings) and apply community detection.
- Map visit frequency per beach using GPS coordinates (geohash clustering).
- Study temporal routines by binning sightings into tidal/diurnal segments.

---

## 8. Contributing & Next Steps

- Use `pre-commit install` to enable linting/formatting hooks.
- Open issues for dataset-specific challenges (labelling noise, occlusions, lighting).
- Extend to multi-modal inputs (acoustic tags, drone footage) where available.

---

## 9. References

- Ultralytics YOLOv8: https://docs.ultralytics.com/
- FaceNet PyTorch: https://github.com/timesler/facenet-pytorch
- DeepFace: https://github.com/serengil/deepface
- DogFaceNet: https://github.com/marvinTeichmann/dogFaceNet

Happy seal spotting! ðŸ¦­
